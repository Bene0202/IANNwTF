{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a65b48b-6580-4a37-b1c2-3a2aa3858bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from sklearn import utils\n",
    "\n",
    "def shuffle (data, targets, minibatchSize):\n",
    "    \n",
    "    data, targets = utils.shuffle(data, targets)\n",
    "    batches = int(len(data)/minibatchSize)+1\n",
    "    minibatchedData = np.empty(shape = [batches,1,minibatchSize,64]) \n",
    "    minibatchedTargets = np.empty(shape = [batches,1,minibatchSize,10])\n",
    "    for i in range (int(len(data)/minibatchSize)):\n",
    "        minibatchedData[i,0] = data[i:i+minibatchSize]\n",
    "        minibatchedTargets[i,0] = targets[i:i+minibatchSize]\n",
    "        i = i+minibatchSize\n",
    "    return minibatchedData, minibatchedTargets\n",
    "\n",
    "def sigmoid (minibatch):\n",
    "    \n",
    "    activationValues = minibatch\n",
    "    with np.nditer(activationValues, op_flags=['readwrite']) as it:\n",
    "        for i in it:\n",
    "            i[...] = 1 / (1+math.exp(-i))\n",
    "    return activationValues\n",
    "\n",
    "def sigmoid_back (error):\n",
    "    with np.nditer(error, op_flags=['readwrite']) as it:\n",
    "            for i in it:\n",
    "                i[...] = sigmoid(i) * (1 - sigmoid(i)) * i\n",
    "    return error\n",
    "\n",
    "def softMax(minibatch):\n",
    "    softmaxValues = minibatch \n",
    "    exponentials = np.exp(minibatch)\n",
    "    for j in range (len(softmaxValues)):\n",
    "        with np.nditer(softmaxValues[j], op_flags=['readwrite']) as it:\n",
    "            for i in it:\n",
    "                i[...] = math.exp(i) / sum(exponentials[j])\n",
    "    return softmaxValues\n",
    "\n",
    "def cce_loss(softmax_output, targets):\n",
    "    loss = []\n",
    "    loged = np.log(softmax_output)\n",
    "    for i in range (len(softmax_output)):\n",
    "        temp = np.dot(targets[i], loged[i])*-1\n",
    "        loss.append(temp)\n",
    "    return loss\n",
    "\n",
    "def loss_back(softmax_out, targets):\n",
    "    return softmax_out - targets\n",
    "\n",
    "def training(epoch,minibatches,targets_batched, net):\n",
    "    losses = []\n",
    "    for e in range(epoch):\n",
    "        for d in range(len(minibatches)):\n",
    "            losses.append(cce_loss(net.forward_step(minibatches[d][0]), targets_batched[d][0]))\n",
    "            net.backward_step(targets_batched[d][0])\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85851cf-57a9-4af3-b71c-a58f9e9223de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
